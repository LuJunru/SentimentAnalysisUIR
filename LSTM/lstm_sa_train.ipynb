{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置常量\n",
    "basic_path = os.getcwd().replace(\"LSTM\", \"\")\n",
    "data_path = basic_path + 'Data/简体30954条_3分类.csv'\n",
    "w2v_path = basic_path + 'Data/WordEmbedding/Word60.model'\n",
    "vocab_dim = 60\n",
    "n_exposures = 1\n",
    "window_size = 7\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "n_iterations = 5\n",
    "input_length = 100\n",
    "batch_size = 32\n",
    "n_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件\n",
    "def get_file(data):\n",
    "    file = pd.read_csv(data)\n",
    "    label = file.iloc[:, 0]\n",
    "    content = file.iloc[:, 1]\n",
    "    return content, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词\n",
    "def segment(text):\n",
    "    return [jieba.lcut(document.replace('\\n', '')) for document in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建词语字典，并返回每个词语的索引，词向量，以及每个句子所对应的词语索引\n",
    "def create_dictionaries(model=None, combined=None):\n",
    "    if (combined is not None) and (model is not None):\n",
    "        gensim_dict = Dictionary()\n",
    "        gensim_dict.doc2bow(model.wv.vocab.keys(), allow_update=True)\n",
    "\n",
    "        w2indx = {v: k + 1 for k, v in gensim_dict.items()}       # 词语的索引,(k->v)=>(v->k)\n",
    "        w2vec = {word: model[word] for word in w2indx.keys()}   # 词语的词向量, (word->model(word))\n",
    "\n",
    "        def parse_dataset(combined):\n",
    "            \"\"\"\n",
    "            :intro: Words become integers\n",
    "            :param combined:\n",
    "            :return:\n",
    "            \"\"\"\n",
    "            data = []\n",
    "            for sentence in combined:\n",
    "                new_txt = []\n",
    "                for word in sentence:\n",
    "                    try:\n",
    "                        new_txt.append(w2indx[word])\n",
    "                    except:\n",
    "                        new_txt.append(0)  # freq < 10->0\n",
    "                data.append(new_txt)\n",
    "            return data\n",
    "        n_combined = parse_dataset(combined)\n",
    "        n_combined = sequence.pad_sequences(n_combined, maxlen=input_length)  # 每个句子所含词语对应的索引，所以句子中含有频数小于10的词语，索引为0\n",
    "        return w2indx, w2vec, n_combined\n",
    "    else:\n",
    "        print('No data provided...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wordvector(w2v_path):\n",
    "    # 载入模型\n",
    "    model = Word2Vec.load(w2v_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(index_dict, word_vectors, combined, y):\n",
    "    n_symbols = len(index_dict) + 1  # 所有单词的索引数\n",
    "    embedding_weights = np.zeros((n_symbols, vocab_dim))  # 初始化 索引为0的词语，词向量全为0\n",
    "    for word, index in index_dict.items():  # 对每个词语对应其词向量\n",
    "        if word in word_vectors:\n",
    "            embedding_weights[index, :] = word_vectors[word]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(combined, y, test_size=0.2)\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes=3)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes=3)\n",
    "    return n_symbols, embedding_weights, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "def train_lstm(n_symbols, embedding_weights, x_train, y_train, x_test, y_test):\n",
    "    print('Defining a Simple Keras Model...')\n",
    "    model = Sequential()  # or Graph or whatever\n",
    "    model.add(Embedding(output_dim=vocab_dim,\n",
    "                        input_dim=n_symbols,\n",
    "                        mask_zero=True,\n",
    "                        weights=[embedding_weights],\n",
    "                        input_length=input_length))  # Adding Input Length\n",
    "    model.add(LSTM(output_dim=30, activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))  # Dense=>全连接层,输出维度=3\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    print('Compiling the Model...')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    print(\"Train...\")\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epoch, verbose=1)\n",
    "\n",
    "    print(\"Evaluate...\")\n",
    "    score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    yaml_string = model.to_yaml()\n",
    "    outfile = open(basic_path + 'LSTM/lstm.yml', 'w')\n",
    "    outfile.write(yaml.dump(yaml_string, default_flow_style=True))\n",
    "    model.save_weights(basic_path + 'LSTM/lstm.h5')\n",
    "    print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "30954 30954\n",
      "Tokenizing & Loading a Word2vec model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/3b/wnl918tx4kj0flqblcc2_7500000gn/T/jieba.cache\n",
      "Loading model cost 0.666 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Arrays for Keras Embedding Layer...\n",
      "x_train.shape and y_train.shape:\n",
      "(24763, 100) (24763, 3)\n",
      "Defining a Simple Keras Model...\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", units=30)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the Model...\n",
      "Train...\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "24763/24763 [==============================] - 384s 16ms/step - loss: 0.9077 - acc: 0.6330\n",
      "Epoch 2/3\n",
      "24763/24763 [==============================] - 403s 16ms/step - loss: 0.8519 - acc: 0.6934\n",
      "Epoch 3/3\n",
      "24763/24763 [==============================] - 419s 17ms/step - loss: 0.8189 - acc: 0.7285\n",
      "Evaluate...\n",
      "6191/6191 [==============================] - 4s 625us/step\n",
      "Test score: [0.8292654038072499, 0.7136165401677942]\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，并保存\n",
    "print('Loading Data...')\n",
    "text, y = get_file(data_path)\n",
    "print(len(text), len(y))\n",
    "print('Tokenizing & Loading a Word2vec model...')\n",
    "index_dict, word_vectors, combined = create_dictionaries(load_wordvector(w2v_path), segment(text))\n",
    "print('Setting up Arrays for Keras Embedding Layer...')\n",
    "n_symbols, embedding_weights, x_train, y_train, x_test, y_test = get_data(index_dict, word_vectors, combined, y)\n",
    "print(\"x_train.shape and y_train.shape:\")\n",
    "print(x_train.shape, y_train.shape)\n",
    "train_lstm(n_symbols, embedding_weights, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
